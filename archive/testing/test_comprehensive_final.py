#!/usr/bin/env python3
"""
Comprehensive test of the final improved prompt.
"""

import json
import time
from openai import OpenAI
import yaml
from pathlib import Path

def test_comprehensive_final():
    """Comprehensive test of all improvements."""
    
    print("üéâ COMPREHENSIVE FINAL PROMPT TEST")
    print("=" * 40)
    print("Testing: Dual component removal + JSON fixes + Logic enforcement + Enhanced examples")
    print()
    
    # Load configuration
    config_path = Path("config/config.yaml")
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)
    
    # Setup OpenAI client
    client = OpenAI(
        api_key=config['openrouter']['api_key'],
        base_url="https://openrouter.ai/api/v1"
    )
    
    model_name = config['models']['primary']['model_name']
    temperature = config['models']['primary']['temperature']
    max_tokens = 2000
    
    print(f"‚úÖ Using model: {model_name}")
    print()
    
    # Load the final prompt
    final_prompt_path = Path("prompts/structured_screening_final.txt")
    with open(final_prompt_path, 'r', encoding='utf-8') as f:
        final_prompt = f.read()
    
    # Comprehensive test cases
    test_cases = [
        {
            "id": "perfect_include",
            "description": "Perfect INCLUDE case - all criteria clear",
            "abstract": """
We evaluate a graduation program in Bangladesh providing monthly cash stipends and productive asset transfers (livestock, equipment) to ultra-poor households. Using a randomized controlled trial with 1,200 households, we measure impacts on income, assets, and expenditure over 24 months. Results show significant improvements in economic outcomes. The study was completed in 2019 and published in 2020.
            """,
            "expected_pattern": "7Y/0N/0U ‚Üí INCLUDE"
        },
        {
            "id": "clear_exclude_no_assets",
            "description": "Clear EXCLUDE - missing productive assets",
            "abstract": """
We examine a cash transfer program in rural India providing monthly payments to ultra-poor women. Using randomized controlled trial methodology, we measure impacts on household consumption. The study was completed in 2018 and published in 2019. No productive assets were provided as part of the intervention.
            """,
            "expected_pattern": "XY/1+N/ZU ‚Üí EXCLUDE (no assets)"
        },
        {
            "id": "clear_exclude_qualitative",
            "description": "Clear EXCLUDE - qualitative study design",
            "abstract": """
This qualitative study explores experiences of microfinance borrowers in rural Kenya through in-depth interviews. We examine how access to small loans affects women's empowerment. The study uses ethnographic methods and was published in 2020.
            """,
            "expected_pattern": "XY/1+N/ZU ‚Üí EXCLUDE (qualitative)"
        },
        {
            "id": "legitimate_maybe",
            "description": "Legitimate MAYBE - truly unclear components",
            "abstract": """
We study a social protection program in Kenya providing support to vulnerable households. The intervention includes various forms of assistance aimed at improving livelihoods. Preliminary analysis suggests positive effects on household welfare measured through survey data.
            """,
            "expected_pattern": "XY/0N/ZU ‚Üí MAYBE (unclear details)"
        },
        {
            "id": "dual_component_confusion_test",
            "description": "Test case that previously had dual component issues",
            "abstract": """
We evaluate the impact of a graduation program providing cash transfers and asset transfers to ultra-poor households in Bangladesh. The program includes monthly cash payments and livestock provision. Using experimental methods, we measure economic outcomes.
            """,
            "expected_pattern": "Should be clearer without dual component criterion"
        }
    ]
    
    results = []
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"üß™ Test {i}/5: {test_case['id']}")
        print(f"   Description: {test_case['description']}")
        print(f"   Expected: {test_case['expected_pattern']}")
        print()
        
        try:
            # Make API call
            print("   üöÄ Making API call...")
            response = client.chat.completions.create(
                model=model_name,
                messages=[
                    {"role": "system", "content": final_prompt},
                    {"role": "user", "content": f"Evaluate this research paper abstract:\n\n{test_case['abstract']}"}
                ],
                temperature=temperature,
                max_tokens=max_tokens
            )
            
            response_text = response.choices[0].message.content
            if not response_text:
                response_text = ""
            else:
                response_text = response_text.strip()
            
            # Try to parse JSON
            parsing_success = False
            criteria_count = {'YES': 0, 'NO': 0, 'UNCLEAR': 0}
            final_decision = "UNCERTAIN"
            decision_reasoning = ""
            
            try:
                # Clean and extract JSON
                cleaned_response = response_text.replace('"', '"').replace('"', '"').replace("'", "'")
                
                if "```json" in cleaned_response:
                    start = cleaned_response.find("```json") + 7
                    end = cleaned_response.find("```", start)
                    if end == -1:
                        cleaned_response = cleaned_response[start:].strip()
                    else:
                        cleaned_response = cleaned_response[start:end].strip()
                elif "```" in cleaned_response:
                    start = cleaned_response.find("```") + 3
                    end = cleaned_response.find("```", start)
                    if end == -1:
                        cleaned_response = cleaned_response[start:].strip()
                    else:
                        cleaned_response = cleaned_response[start:end].strip()
                
                result_data = json.loads(cleaned_response)
                parsing_success = True
                
                # Count criteria assessments (now 7 instead of 8)
                criteria_eval = result_data.get('criteria_evaluation', {})
                for criterion_key, criterion_data in criteria_eval.items():
                    if isinstance(criterion_data, dict):
                        assessment = criterion_data.get('assessment', 'UNCLEAR')
                        if assessment in criteria_count:
                            criteria_count[assessment] += 1
                
                final_decision = result_data.get('final_decision', 'UNCERTAIN')
                decision_reasoning = result_data.get('decision_reasoning', 'No reasoning')
                
                print(f"   ‚úÖ JSON parsing: SUCCESS")
                
            except json.JSONDecodeError as e:
                print(f"   ‚ùå JSON parsing: FAILED ({e})")
                parsing_success = False
                final_decision = "UNCERTAIN"
                decision_reasoning = f"Parsing failed: {str(e)}"
            
            # Display results
            yes_count = criteria_count['YES']
            no_count = criteria_count['NO']
            unclear_count = criteria_count['UNCLEAR']
            unclear_rate = unclear_count / 7 * 100  # Now 7 criteria
            
            print(f"   üìä Criteria: {yes_count}Y/{no_count}N/{unclear_count}U (out of 7)")
            print(f"   üéØ Decision: {final_decision}")
            print(f"   ‚ùì UNCLEAR rate: {unclear_rate:.1f}%")
            print(f"   üí≠ Reasoning: {decision_reasoning[:80]}...")
            print()
            
            # Validate decision logic
            logic_correct = False
            if no_count > 0 and final_decision == "EXCLUDE":
                logic_correct = True
                print("   ‚úÖ Correct logic: NO criteria ‚Üí EXCLUDE")
            elif yes_count == 7 and no_count == 0 and unclear_count == 0 and final_decision == "INCLUDE":
                logic_correct = True
                print("   ‚úÖ Correct logic: All YES ‚Üí INCLUDE")
            elif no_count == 0 and unclear_count > 0 and final_decision == "MAYBE":
                logic_correct = True
                print("   ‚úÖ Correct logic: No NO, some UNCLEAR ‚Üí MAYBE")
            else:
                print(f"   ‚ö†Ô∏è  Logic issue: {yes_count}Y/{no_count}N/{unclear_count}U ‚Üí {final_decision}")
            
            # Assessment against expectations
            if parsing_success:
                print("   ‚úÖ JSON parsing successful")
            
            if unclear_rate <= 20:
                print("   ‚úÖ Low UNCLEAR rate")
            elif unclear_rate <= 40:
                print("   üü° Moderate UNCLEAR rate")
            else:
                print("   ‚ùå High UNCLEAR rate")
            
            results.append({
                'test_id': test_case['id'],
                'parsing_success': parsing_success,
                'criteria_count': criteria_count,
                'final_decision': final_decision,
                'decision_reasoning': decision_reasoning,
                'unclear_rate': unclear_rate,
                'logic_correct': logic_correct
            })
            
            print()
            time.sleep(2)  # Rate limiting
            
        except Exception as e:
            print(f"   ‚ùå API call failed: {e}")
            continue
    
    # Overall summary
    print("üéâ COMPREHENSIVE TEST SUMMARY")
    print("=" * 35)
    
    if results:
        parsing_success_rate = sum(1 for r in results if r['parsing_success']) / len(results) * 100
        logic_success_rate = sum(1 for r in results if r['logic_correct']) / len(results) * 100
        avg_unclear_rate = sum(r['unclear_rate'] for r in results) / len(results)
        
        print(f"‚úÖ Tests completed: {len(results)}/5")
        print(f"üîß JSON parsing success: {parsing_success_rate:.1f}%")
        print(f"üéØ Decision logic accuracy: {logic_success_rate:.1f}%")
        print(f"‚ùì Average UNCLEAR rate: {avg_unclear_rate:.1f}% (7 criteria)")
        print()
        
        # Detailed results
        print("üìã INDIVIDUAL TEST RESULTS:")
        for result in results:
            parsing = "‚úÖ" if result['parsing_success'] else "‚ùå"
            logic = "‚úÖ" if result['logic_correct'] else "‚ùå"
            unclear = result['unclear_rate']
            decision = result['final_decision']
            criteria = result['criteria_count']
            print(f"   ‚Ä¢ {result['test_id']}: {parsing}Parse {logic}Logic | {criteria['YES']}Y/{criteria['NO']}N/{criteria['UNCLEAR']}U ‚Üí {decision} | {unclear:.1f}%U")
        
        print()
        
        # Final assessment
        print("üîç FINAL ASSESSMENT:")
        
        if parsing_success_rate == 100:
            print("üéâ EXCELLENT: JSON parsing completely reliable!")
        elif parsing_success_rate >= 80:
            print("‚úÖ GOOD: JSON parsing mostly reliable")
        else:
            print("‚ö†Ô∏è  NEEDS WORK: JSON parsing issues remain")
        
        if logic_success_rate == 100:
            print("üéâ EXCELLENT: Decision logic perfect!")
        elif logic_success_rate >= 80:
            print("‚úÖ GOOD: Decision logic mostly correct")
        else:
            print("‚ö†Ô∏è  NEEDS WORK: Decision logic issues remain")
        
        if avg_unclear_rate <= 20:
            print("üéâ EXCELLENT: UNCLEAR rates very low!")
        elif avg_unclear_rate <= 30:
            print("‚úÖ GOOD: UNCLEAR rates reasonable")
        elif avg_unclear_rate <= 40:
            print("üü° MODERATE: Some optimization possible")
        else:
            print("‚ö†Ô∏è  HIGH: UNCLEAR rates need improvement")
        
        # Key improvements achieved
        print()
        print("‚úÖ KEY IMPROVEMENTS ACHIEVED:")
        print("‚Ä¢ Dual component criterion removed (eliminated 89.5% confusion source)")
        print("‚Ä¢ Enhanced cash/asset examples for clarity")
        print("‚Ä¢ Strengthened decision logic enforcement") 
        print("‚Ä¢ Improved JSON formatting robustness")
        print("‚Ä¢ Reduced from 8 to 7 criteria (faster processing)")
        
        # Save results
        output_file = Path("data/output/comprehensive_final_test_results.json")
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        print(f"üíæ Results saved: {output_file}")
        
        # Production readiness
        print()
        if parsing_success_rate >= 90 and logic_success_rate >= 90 and avg_unclear_rate <= 30:
            print("üöÄ PRODUCTION READY: Final prompt meets quality thresholds!")
        else:
            print("üîß NEEDS REFINEMENT: Some issues remain before production deployment")
            
    else:
        print("‚ùå No results to analyze")

if __name__ == "__main__":
    test_comprehensive_final()